---
layout: page
# title: Home
show_sidebar: true
# hero_image: img/sonivis7.png
title: Audio-Visual Analytics
subtitle: Identifying Research Gaps for Integrating Sonification and Visualization
# hide_hero: true
---

<!-- <section class="hero is-medium is-bold is-primary">
    <div class="hero-body">
        <div class="container">
            <p class="subtitle is-3">{{ page.subtitle }}</p>
            <figure class="image">
                <img src="img/sonivis7.png">
            </figure>
        </div>
    </div>
</section> -->

![Conceptual process of audio-visual data analysis: data are transformed and encoded to form visual and auditory representations for the human analyst who interactively steers the idiom for their data analysis](/img/sonivis7.png){:class="img-responsive"}

Visualization and sonification are two approaches for conveying data to humans based on complementary high-bandwidth information processing systems. Kramer et al. defined sonification as “the use of nonspeech audio to convey information.” Tamara Munzner defines visualization as follows: “Computer-based visualization systems provide visual representations of datasets designed to help people carry out tasks more effectively.” Both visualization and sonification address the purpose of involving human analysts in data analysis. There are several similarities between the methods and design theories of both approaches, such as the use of perceptual variables to encode data attributes, and the role of interaction in manipulating the data representations.

Some illustrative examples:

<div class="columns is-variable is-8">
  <div class="column">
    <a href="http://listen.hatnote.com/">
    <figure class="image is-16by9">
      <img src="img/listen-wikipedia_320.jpg" alt="Screenshot of Listen to Wikipedia">
    </figure>
    Listen to Wikipedia</a>
  </div>
  <div class="column">
    <a href="https://enzodesena.github.io/covid-listening-project/">
    <figure class="image is-16by9">
      <img src="img/covid-listen_320.jpg" alt="Screenshot of COVID-19 Listening Project">
    </figure>
    COVID-19 Listening Project</a>
  </div>
  <div class="column">
    <a href="https://vimeo.com/182985506">
    <figure class="image is-16by9">
      <img src="img/support-dense_320.jpg" alt="Screenshot of Parallel Coordinates with Sonification Support">
    </figure>
    Sonification Support for Dense Data Displays</a>
  </div>
</div>

Over the recent decades, both fields have established research communities, theoretical frameworks, and toolkit support. Although extensive research has been carried out both on the auditory andvisual representation of data, comparatively little is known about their systematic and complementary combination for data analysis. One example of multimodal research is Keith Nesbitt’s dissertation. Also, Walker and Kramer pointed out that research on the design and the use of multimodal sonification is important to drive sonification and visualization research forward. There are potential powerful synergies in combining both modalities to address the individual limitations of each one. Nevertheless, existing research on combinations has often focused only on one of the modalities.

Actual multimodal approaches should be based on complementary and mutually supportive interplays between data representations on the visual and the auditory domain.
This workshop series aims to build a community of researchers from both fields, to work towards a common language, and to find research gaps for a combined visualization and sonification theory.

**Upcoming events:**
* [AVAC Meet-Up: t.b.a. (autumn 2022)](meetups)

**Past events:**
* [Application Spotlight @ IEEE VIS (Oklahoma City, USA/hybrid): October 20, 2022](vis2022)
* [3rd Workshop on Audio-Visual Analytics @ Int. Conf. Advanced Visual Interfaces: June 7, 2022](avi2022)
* [Workshop @ IEEE VIS (virtual): October 25, 2021](vis2021)
* [Workshop @ Audio Mostly (virtual): September 3, 2021](am2021)
